N: 1
batch_size: 16
batch_size_test: 23
amt_samples: 17
nrm_lr: 0.0012
perception_lr: 0.003
predict_only: True
nrm_loss: 'mse'
perception_loss: 'log-q'
percept_loss_pref: 1
policy: 'off'
hidden_size: 450
K_beliefs: 100
dirichlet_lr: 0.003
dirichlet_iters: 50
dirichlet_init: 0.01
dirichlet_L2: 900000
layers: 3
DEBUG: True
test: False
prune: True
