N: 3
batch_size: 16
amt_samples: 1200
nrm_lr: 0.0012
perception_lr: 0.0012
nrm_loss: 'bce'
perception_loss: 'log-q'
policy: 'both'
hidden_size: 1000
K_beliefs: 1000
dirichlet_lr: 0.0003
dirichlet_iters: 0.5
dirichlet_init: 0.5